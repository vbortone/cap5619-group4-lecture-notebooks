{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXACkAtfNpG0"
   },
   "source": [
    "# The Attention Mechanism\n",
    "The goal of this notebook is to obtain a mathematical view of the attention mechanism of transformer models. \n",
    "\n",
    "[The Reference Colaboratory Notebook was written by Manuel Romero](https://colab.research.google.com/drive/1rPk3ohrmVclqhH7uQ7qys4oznDdAhpzF)\n",
    "\n",
    "[A Medium article was written by Raimi Karim](https://towardsdatascience.com/illustrated-self-attention-2d627e33b20a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yidFc0HsWzo8"
   },
   "source": [
    "#Step 1: Represent the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LspsihZRK5OW",
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2024-02-28T17:19:53.695560Z",
     "start_time": "2024-02-28T17:19:53.688850Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image     #This is used for rendering images in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "veRoFjFRNXwJ",
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2024-02-28T17:19:53.883480Z",
     "start_time": "2024-02-28T17:19:53.696570Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JLe9lWCJNogW",
    "outputId": "ff872b45-fb1a-4c9b-d1c6-a23be59a2c48",
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2024-02-28T17:19:53.895487Z",
     "start_time": "2024-02-28T17:19:53.884497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Input : 3 inputs, d_model=4\n",
      "[[1. 0. 1. 0.]\n",
      " [0. 2. 0. 2.]\n",
      " [1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 1: Input : 3 inputs, d_model=4\")\n",
    "x =np.array([[1.0, 0.0, 1.0, 0.0],   # Input 1\n",
    "             [0.0, 2.0, 0.0, 2.0],   # Input 2\n",
    "             [1.0, 1.0, 1.0, 1.0]])  # Input 3\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3_VzGEFW4-q"
   },
   "source": [
    "#Step 2: Initializing the weight matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JZImwtHPN91V",
    "outputId": "7adf4dec-ba21-4cfe-a5e8-9a9ff882b7c2",
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2024-02-28T17:19:53.901251Z",
     "start_time": "2024-02-28T17:19:53.895487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: weights 3 dimensions x d_model=4\n",
      "w_query\n",
      "[[1 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 2: weights 3 dimensions x d_model=4\")\n",
    "print(\"w_query\")\n",
    "w_query =np.array([[1, 0, 1],\n",
    "                   [1, 0, 0],\n",
    "                   [0, 0, 1],\n",
    "                   [0, 1, 1]])\n",
    "print(w_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7kRBS7MUOFgV",
    "outputId": "6e4d223b-f82d-42ea-da87-da47197c7446",
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2024-02-28T17:19:53.907131Z",
     "start_time": "2024-02-28T17:19:53.902270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_key\n",
      "[[0 0 1]\n",
      " [1 1 0]\n",
      " [0 1 0]\n",
      " [1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"w_key\")\n",
    "w_key =np.array([[0, 0, 1],\n",
    "                 [1, 1, 0],\n",
    "                 [0, 1, 0],\n",
    "                 [1, 1, 0]])\n",
    "print(w_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Napm2VtkOIEN",
    "outputId": "1e9e4418-cc84-46bd-c009-6cfa4bbd949c",
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2024-02-28T17:19:53.911957Z",
     "start_time": "2024-02-28T17:19:53.907131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_value\n",
      "[[0 2 0]\n",
      " [0 3 0]\n",
      " [1 0 3]\n",
      " [1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"w_value\")\n",
    "w_value = np.array([[0, 2, 0],\n",
    "                    [0, 3, 0],\n",
    "                    [1, 0, 3],\n",
    "                    [1, 1, 0]])\n",
    "print(w_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpZQl6nrXBmE"
   },
   "source": [
    "#Step 3: Matrix multiplication to obtain Q, K, and V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JqapIgfDOQ7d",
    "outputId": "06041946-1fbb-4900-a54d-2eaa799a3051",
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2024-02-28T17:19:53.997575Z",
     "start_time": "2024-02-28T17:19:53.911957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Matrix multiplication to obtain Q,K,V\n",
      "Queries: x * w_query\n",
      "[[1. 0. 2.]\n",
      " [2. 2. 2.]\n",
      " [2. 1. 3.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 3: Matrix multiplication to obtain Q,K,V\")\n",
    "\n",
    "print(\"Queries: x * w_query\")\n",
    "Q=np.matmul(x,w_query)\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NmfMln1Wmv73",
    "outputId": "77e75f47-f559-4043-d918-6303bdb33cc4",
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2024-02-28T17:19:54.003149Z",
     "start_time": "2024-02-28T17:19:53.997575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Matrix multiplication to obtain Q,K,V\n",
      "Keys: x * w_key\n",
      "[[0. 1. 1.]\n",
      " [4. 4. 0.]\n",
      " [2. 3. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 3: Matrix multiplication to obtain Q,K,V\")\n",
    "\n",
    "print(\"Keys: x * w_key\")\n",
    "K=np.matmul(x,w_key)\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v3Asv-8mOWkN",
    "outputId": "9ee01da7-15d0-403d-95c5-ce757af0b352",
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2024-02-28T17:19:54.017096Z",
     "start_time": "2024-02-28T17:19:54.003149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values: x * w_value\n",
      "[[1. 2. 3.]\n",
      " [2. 8. 0.]\n",
      " [2. 6. 3.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Values: x * w_value\")\n",
    "V=np.matmul(x,w_value)\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVkuSeL9XGmE"
   },
   "source": [
    "#Step 4: Scaled attention scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gfgRAHUuOp5c",
    "outputId": "08668ae2-ea63-4093-851c-e85417478595",
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2024-02-28T17:19:54.022959Z",
     "start_time": "2024-02-28T17:19:54.017096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4: Scaled Attention Scores\n",
      "[[ 2.  4.  4.]\n",
      " [ 4. 16. 12.]\n",
      " [ 4. 12. 10.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 4: Scaled Attention Scores\")\n",
    "k_d=1   #square root of k_d simplified to 1 for this example\n",
    "attention_scores = (Q @ K.transpose())/k_d\n",
    "print(attention_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNknYJ-rXLG0"
   },
   "source": [
    "#Step 5: Scaled softmax attention scores for each vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hg2t6KuNOjzM",
    "outputId": "fb04d37f-e70d-4442-bc8d-91cdd3be960f",
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2024-02-28T17:19:54.030117Z",
     "start_time": "2024-02-28T17:19:54.023969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: Scaled softmax attention_scores for each vector\n",
      "[0.06337894 0.46831053 0.46831053]\n",
      "[6.03366485e-06 9.82007865e-01 1.79861014e-02]\n",
      "[2.95387223e-04 8.80536902e-01 1.19167711e-01]\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 5: Scaled softmax attention_scores for each vector\")\n",
    "attention_scores[0]=softmax(attention_scores[0])\n",
    "attention_scores[1]=softmax(attention_scores[1])\n",
    "attention_scores[2]=softmax(attention_scores[2])\n",
    "print(attention_scores[0])\n",
    "print(attention_scores[1])\n",
    "print(attention_scores[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-MhPWboeXTDy"
   },
   "source": [
    "#Step 6: The final attention representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R4Es7A7NOvjD",
    "outputId": "f78d8072-c429-4214-dc44-7f246ff75bda",
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2024-02-28T17:19:54.036450Z",
     "start_time": "2024-02-28T17:19:54.030117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: attention value obtained by score1/k_d * V\n",
      "[1. 2. 3.]\n",
      "[2. 8. 0.]\n",
      "[2. 6. 3.]\n",
      "Attention 1\n",
      "[0.06337894 0.12675788 0.19013681]\n",
      "Attention 2\n",
      "[0.93662106 3.74648425 0.        ]\n",
      "Attention 3\n",
      "[0.93662106 2.80986319 1.40493159]\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 6: attention value obtained by score1/k_d * V\")\n",
    "print(V[0])\n",
    "print(V[1])\n",
    "print(V[2])\n",
    "print(\"Attention 1\")\n",
    "attention1=attention_scores[0].reshape(-1,1)\n",
    "attention1=attention_scores[0][0]*V[0]\n",
    "print(attention1)\n",
    "\n",
    "print(\"Attention 2\")\n",
    "attention2=attention_scores[0][1]*V[1]\n",
    "print(attention2)\n",
    "\n",
    "print(\"Attention 3\")\n",
    "attention3=attention_scores[0][2]*V[2]\n",
    "print(attention3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XzFUN5-XZUK"
   },
   "source": [
    "#Step 7: Summing up the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uBDKhaCvOzXj",
    "outputId": "8a4f2f33-cb1b-43ba-c315-b880c861da90",
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2024-02-28T17:19:54.042145Z",
     "start_time": "2024-02-28T17:19:54.037300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7: summed the results to create the first line of the output matrix\n",
      "[1.93662106 6.68310531 1.59506841]\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 7: summed the results to create the first line of the output matrix\")\n",
    "attention_input1=attention1+attention2+attention3\n",
    "print(attention_input1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-WNXZBrXeEy"
   },
   "source": [
    "#Step 8: Steps 1 to 7 for all the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iEjgRcqHO4ik",
    "outputId": "8db5e9ba-827b-4b69-ed54-e569faf58dbb",
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2024-02-28T17:19:54.057693Z",
     "start_time": "2024-02-28T17:19:54.043158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8: Step 1 to 7 for inputs 1 to 3\n",
      "[[0.74348464 0.03108524 0.38595476 0.04740278 0.05690497 0.49229253\n",
      "  0.90933762 0.08621274 0.05688699 0.32554802 0.3287342  0.2079422\n",
      "  0.34546608 0.7791821  0.18401724 0.274074   0.17272442 0.15856636\n",
      "  0.16998304 0.11117685 0.23642192 0.91463878 0.44853715 0.3369912\n",
      "  0.73883096 0.36935393 0.95774932 0.99026274 0.31982828 0.08616066\n",
      "  0.3561173  0.22891757 0.886296   0.96349539 0.69310185 0.04619317\n",
      "  0.38612744 0.92507682 0.05446979 0.78454062 0.63128681 0.27091767\n",
      "  0.64532498 0.27319178 0.1521132  0.50033529 0.63854618 0.69431338\n",
      "  0.91751191 0.95554966 0.10433768 0.0830124  0.6896154  0.97377707\n",
      "  0.83882706 0.5943972  0.48355824 0.21076418 0.85613028 0.02486468\n",
      "  0.35955151 0.27227195 0.688496   0.16547551]\n",
      " [0.77790863 0.67193923 0.83731051 0.31749792 0.09163877 0.55667935\n",
      "  0.13936783 0.7122765  0.82493315 0.17514307 0.11448561 0.81768266\n",
      "  0.33622209 0.76146609 0.47093224 0.55891132 0.12995407 0.90788132\n",
      "  0.6126978  0.77508403 0.1562279  0.25069427 0.18166702 0.09817639\n",
      "  0.85660436 0.44259171 0.85938646 0.7598325  0.66934796 0.77491627\n",
      "  0.8193275  0.75729845 0.21402108 0.6954186  0.43001255 0.17236092\n",
      "  0.59239142 0.31673973 0.584617   0.26226068 0.90885619 0.72769419\n",
      "  0.84555304 0.5049037  0.8939058  0.58280569 0.54116905 0.24793579\n",
      "  0.45749004 0.39608838 0.07262551 0.39745783 0.28643291 0.75651702\n",
      "  0.38273073 0.76285798 0.63060322 0.19572155 0.78193952 0.92191916\n",
      "  0.17991556 0.84871496 0.45215032 0.10296746]\n",
      " [0.52685746 0.17417296 0.07519428 0.24520336 0.01153134 0.86838741\n",
      "  0.27798725 0.34621033 0.64134265 0.67353596 0.28179131 0.33113848\n",
      "  0.14206894 0.13234076 0.52648968 0.5920211  0.72171695 0.61467503\n",
      "  0.89209082 0.55163839 0.55511734 0.12781033 0.74375938 0.08997773\n",
      "  0.66978372 0.79845857 0.67755251 0.59704058 0.08760626 0.66122641\n",
      "  0.15454795 0.37812652 0.04578569 0.74667418 0.50862629 0.81067581\n",
      "  0.36075655 0.89030732 0.71001708 0.94848149 0.66958715 0.85506707\n",
      "  0.45735103 0.30012311 0.41219233 0.73089848 0.11114793 0.57087873\n",
      "  0.94387851 0.8409796  0.76133524 0.19936304 0.93464801 0.54947826\n",
      "  0.15753641 0.43194306 0.42378257 0.41446012 0.03638929 0.48488473\n",
      "  0.36142963 0.95529979 0.07989511 0.67125133]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 8: Step 1 to 7 for inputs 1 to 3\")\n",
    "#We assume we have 3 results with learned weights (they were not trained in this example)\n",
    "#We assume we are implementing the original Transformer paper. We will have 3 results of 64 dimensions each\n",
    "attention_head1=np.random.random((3, 64))\n",
    "print(attention_head1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Byoi-zImXjAC"
   },
   "source": [
    "#Step 9: The output of the heads of the attention sublayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QI50dkZ1O630",
    "outputId": "676f5c25-b484-488b-bcd8-800a763523bd",
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2024-02-28T17:19:54.063347Z",
     "start_time": "2024-02-28T17:19:54.057693Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9: We assume we have trained the 8 heads of the attention sub-layer\n",
      "shape of one head (3, 64) dimension of 8 heads 512\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 9: We assume we have trained the 8 heads of the attention sub-layer\")\n",
    "z0h1=np.random.random((3, 64))\n",
    "z1h2=np.random.random((3, 64))\n",
    "z2h3=np.random.random((3, 64))\n",
    "z3h4=np.random.random((3, 64))\n",
    "z4h5=np.random.random((3, 64))\n",
    "z5h6=np.random.random((3, 64))\n",
    "z6h7=np.random.random((3, 64))\n",
    "z7h8=np.random.random((3, 64))\n",
    "print(\"shape of one head\",z0h1.shape,\"dimension of 8 heads\",64*8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJes4XBjXmUm"
   },
   "source": [
    "#Step 10: Concatenation of the output of the heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3n87LE92_Puf",
    "outputId": "0a0fe563-9d35-470a-e12f-05df996c1183",
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2024-02-28T17:19:54.069487Z",
     "start_time": "2024-02-28T17:19:54.063347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10: Concatenation of heads 1 to 8 to obtain the original 8x64=512 output dimension of the model\n",
      "[[0.87761897 0.35199591 0.47342937 ... 0.54710165 0.05753752 0.37410391]\n",
      " [0.78824805 0.91744616 0.74708031 ... 0.78924099 0.15999264 0.1205283 ]\n",
      " [0.58745204 0.86930756 0.08142615 ... 0.79199385 0.16758095 0.38145717]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 10: Concatenation of heads 1 to 8 to obtain the original 8x64=512 output dimension of the model\")\n",
    "output_attention=np.hstack((z0h1,z1h2,z2h3,z3h4,z4h5,z5h6,z6h7,z7h8))\n",
    "print(output_attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJLl4Jf3fPLh"
   },
   "source": [
    "And now with Hugging Face in one line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "CZIRvcRmfTPb",
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2024-02-28T17:20:03.324488Z",
     "start_time": "2024-02-28T17:19:54.069487Z"
    }
   },
   "outputs": [],
   "source": [
    "#@title Transformer Installation\n",
    "!pip -q install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cNwLYc-SfXdF",
    "outputId": "fb4568a2-5b1c-499a-875f-ce6267b9b610",
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2024-02-28T17:20:17.108096Z",
     "start_time": "2024-02-28T17:20:03.325500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google-t5/t5-base and revision 686f1db (https://huggingface.co/google-t5/t5-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9486e53f16c542b7b3d74ee03098df83"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b483f9d520f4593bbbe2c52e05a5e42"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2fe03930ccd7406abec064c01ae96304"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c03d62ff3df424b8b9337bef1f8c0d1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2bca5434c0f44b5b3f77464430b6e83"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\projects\\UCF\\CAP5619\\lecture_notebooks\\.venv\\Lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:171: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on google-t5/t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': \"Il est facile de traduire des langues à l'aide de transformateurs\"}]\n"
     ]
    }
   ],
   "source": [
    "#@title Retrieve pipeline of modules and choose English to French translation\n",
    "from transformers import pipeline\n",
    "translator = pipeline(\"translation_en_to_fr\")\n",
    "#One line of code!\n",
    "print(translator(\"It is easy to translate languages with transformers\", max_length=40))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Multi_Head_Attention_Sub_Layer (1).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
